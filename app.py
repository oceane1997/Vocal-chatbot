# app_voice_chatbot.py â€” Chatbot vocal (Candide) : texte OU voix (micro navigateur / fichier)

import streamlit as st
import nltk
from typing import Optional
from pathlib import Path
import tempfile
import speech_recognition as sr

# ============================
# Ã‰tape 1 â€” Imports & setup
# ============================
st.set_page_config(page_title="Chatbot vocal", page_icon="ðŸ—£ï¸")
st.title("ðŸ—£ï¸ Chatbot vocal (Candide)")

# TÃ©lÃ©chargements NLTK (inoffensifs si dÃ©jÃ  prÃ©sents)
for pkg in ["punkt", "stopwords", "punkt_tab"]:
    try:
        nltk.download(pkg, quiet=True)
    except Exception:
        pass

st.success("Imports OK : Streamlit, SpeechRecognition, NLTK")

# ============================
# Ã‰tape 2 â€” Chatbot : corpus + prÃ©traitement
# ============================
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer
from nltk.tokenize import word_tokenize, sent_tokenize

STOPS_FR = set(stopwords.words("french"))
STEM_FR = SnowballStemmer("french")

def preprocess(sentence: str) -> list[str]:
    """Tokenisation FR, minuscules, lettres uniquement, stopwords, stemming."""
    toks = word_tokenize(sentence, language="french")
    toks = [t.lower() for t in toks if t.isalpha()]
    toks = [t for t in toks if t not in STOPS_FR]
    toks = [STEM_FR.stem(t) for t in toks]
    return toks

@st.cache_data
def load_corpus(path: str = "corpus.txt"):
    p = Path(path)
    if not p.exists():
        return None, None, f"â—ï¸ Fichier {path} introuvable. Place-le Ã  cÃ´tÃ© de app_voice_chatbot.py."
    text = p.read_text(encoding="utf-8").replace("\n", " ")
    sentences = sent_tokenize(text, language="french")
    return text, sentences, None

@st.cache_data
def build_processed(sentences: list[str]):
    """CrÃ©e les ensembles de tokens (pour similaritÃ© Jaccard)."""
    return [set(preprocess(s)) for s in sentences]

st.header("Ã‰tape 2/6 â€” Corpus & prÃ©traitement")
full_text, sentences, err = load_corpus("corpus.txt")
if err:
    st.error(err)
    st.stop()

corpus_processed = build_processed(sentences)
st.success(f"Corpus chargÃ© âœ… â€” {len(sentences)} phrases.")
st.caption("PrÃ©traitement OK (stopwords FR + stemming).")

# Stockage robuste pour rÃ©utiliser mÃªme aprÃ¨s reruns Streamlit
if "sentences" not in st.session_state:
    st.session_state["sentences"] = sentences
if "corpus_processed" not in st.session_state:
    st.session_state["corpus_processed"] = corpus_processed

# ============================
# Ã‰tape 3 â€” Transcription (fichier / blob micro navigateur)
# ============================
def transcribe_audio_file(uploaded_file, language: str = "fr-FR"):
    """
    Transcrit un fichier audio/flux (WAV/FLAC/WEBM) avec Google Web Speech API.
    uploaded_file : st.file_uploader ou st.audio_input (a un .read()).
    Renvoie (message_utilisateur, debug_details_ou_None)
    """
    r = sr.Recognizer()

    # Ã‰crire l'upload dans un fichier temporaire avec extension
    suffix = ".wav"
    try:
        name = getattr(uploaded_file, "name", None)
        if name and "." in name:
            suffix = "." + name.split(".")[-1].lower()
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = Path(tmp.name)
    except Exception as e:
        return ("â—ï¸ Impossible de crÃ©er un fichier temporaire pour l'audio.", f"{type(e).__name__}: {e}")

    try:
        with sr.AudioFile(str(tmp_path)) as source:
            # lÃ©ger ajustement du bruit
            r.adjust_for_ambient_noise(source, duration=0.2)
            audio = r.record(source)
        text = r.recognize_google(audio, language=language)
        return (text, None)

    except sr.UnknownValueError as e:
        return ("â—ï¸ Lâ€™API nâ€™a pas compris lâ€™audio. Parlez plus clairement ou vÃ©rifiez la langue.", f"{type(e).__name__}")
    except sr.RequestError as e:
        return ("â—ï¸ Erreur de service (rÃ©seau/quota). VÃ©rifiez Internet et rÃ©essayez.", f"{type(e).__name__}: {e}")
    except ValueError as e:
        return ("â—ï¸ Format non supportÃ©. Utilisez un fichier WAV ou FLAC.", f"{type(e).__name__}: {e}")
    except Exception as e:
        return ("â—ï¸ Erreur inattendue lors de la transcription.", f"{type(e).__name__}: {e}")
    finally:
        try:
            tmp_path.unlink(missing_ok=True)
        except Exception:
            pass

# (facultatif) petit test de la transcription seule
#with st.expander("ðŸ§ª Ã‰tape 3/6 â€” Tester la transcription (fichier)"):
    lang_test = st.selectbox("Langue audio (test)", ["fr-FR", "en-US", "es-ES"], index=0, key="lang_test")
    test_audio = st.file_uploader("Choisir un audio (WAV/FLAC)", type=["wav", "flac"], key="test_audio")
    if st.button("Tester la transcription", key="btn_test_trans"):
        if not test_audio:
            st.warning("SÃ©lectionnez un fichier audio d'abord.")
        else:
            with st.spinner("Transcription en cours..."):
                msg, dbg = transcribe_audio_file(test_audio, language=lang_test)
            if msg.startswith("â—ï¸"):
                st.error(msg)
                if dbg:
                    st.code(dbg)
            else:
                st.success("Transcription OK")
                st.write(msg)

# ============================
# Ã‰tape 4 â€” Chatbot (Jaccard) + routeur texte/audio
# ============================
def get_most_relevant_sentence(query: str, sentences: list[str], corpus_processed: list[set]) -> tuple[str, float]:
    """Renvoie (phrase_la_plus_pertinente, score_jaccard)."""
    q = set(preprocess(query))
    if not q:
        return ("(Votre question est vide aprÃ¨s prÃ©traitement.)", 0.0)

    best_idx, best_score = -1, 0.0
    for i, s_tokens in enumerate(corpus_processed):
        inter = q & s_tokens
        union = q | s_tokens
        score = (len(inter) / len(union)) if union else 0.0
        if score > best_score:
            best_score, best_idx = score, i

    if best_idx == -1:
        return ("(Aucune phrase trouvÃ©e.)", 0.0)
    return (sentences[best_idx], best_score)

def chatbot(question: str, sentences: list[str], corpus_processed: list[set], min_score: float = 0.15) -> str:
    """Si le score Jaccard < min_score â†’ on demande de reformuler."""
    best_sentence, score = get_most_relevant_sentence(question, sentences, corpus_processed)
    if score < min_score:
        return "Je nâ€™ai pas trouvÃ© de passage assez proche. Peux-tu reformuler ta question ?"
    return best_sentence

def reply_from_text_or_audio(
    text_input: Optional[str],
    audio_file,
    language_code: str,
    sentences: list[str],
    corpus_processed: list[set],
    min_score: float = 0.15,
):
    """
    - Si text_input est non vide â†’ chatbot(question).
    - Sinon, si audio_file est fourni â†’ transcription puis chatbot(transcription).
    - Renvoie (rÃ©ponse, debug) ; debug != None seulement si erreur de transcription.
    """
    if text_input and text_input.strip():
        question = text_input.strip()
        answer = chatbot(question, sentences, corpus_processed, min_score=min_score)
        return (answer, None)

    if audio_file is not None:
        msg, dbg = transcribe_audio_file(audio_file, language=language_code)
        if msg.startswith("â—ï¸"):
            return (msg, dbg)
        answer = chatbot(msg, sentences, corpus_processed, min_score=min_score)
        return (answer, None)

    return ("â—ï¸ Fournis soit une question texte, soit un fichier audio.", None)

# ============================
# Ã‰tape 5 â€” Interface : Texte OU Audio + Micro navigateur
# ============================
st.header("Ã‰tape 5/6 â€” Pose ta question (texte OU audio)")

# ParamÃ¨tres
colA, colB = st.columns([1, 1])
with colA:
    lang = st.selectbox("Langue de l'audio", ["fr-FR", "en-US", "es-ES"], index=0)
with colB:
    min_score = st.slider("Seuil de pertinence (Jaccard)", 0.0, 1.0, 0.15, 0.01,
                          help="Si le score < seuil â†’ on demande de reformuler.")

# EntrÃ©es possibles
txt_question = st.text_input("Question (texte)")
audio_file = st.file_uploader("OU dÃ©pose un fichier audio (WAV/FLAC)", type=["wav", "flac"])

if txt_question and audio_file:
    st.info("Texte **prioritaire** : si vous fournissez les deux, le texte est utilisÃ© et lâ€™audio est ignorÃ©.")

# Bouton principal
if st.button("RÃ©pondre", key="btn_text_or_file"):
    with st.spinner("Analyse en cours..."):
        answer, debug = reply_from_text_or_audio(
            text_input=txt_question,
            audio_file=audio_file,
            language_code=lang,
            sentences=st.session_state["sentences"],
            corpus_processed=st.session_state["corpus_processed"],
            min_score=min_score,
        )

    st.markdown("**RÃ©ponse du chatbot :**")
    if answer.startswith("â—ï¸"):
        st.error(answer)
        if debug:
            with st.expander("DÃ©tails techniques"):
                st.code(debug)
    else:
        st.success("RÃ©ponse trouvÃ©e âœ…")
        st.write(answer)

# Micro (navigateur) â€” pas de PyAudio requis
st.markdown("---")
st.subheader("ðŸŽ™ï¸ Micro (navigateur) â€” poser une question Ã  voix haute")

blob = st.audio_input("Appuie pour enregistrer puis relÃ¢che")

if st.button("RÃ©pondre (depuis le micro)", key="btn_mic"):
    if not blob:
        st.warning("Enregistre dâ€™abord un segment au micro.")
    else:
        with st.spinner("Transcription en cours..."):
            msg, dbg = transcribe_audio_file(blob, language=lang)

        if msg.startswith("â—ï¸"):
            st.error(msg)
            if dbg:
                with st.expander("DÃ©tails techniques"):
                    st.code(dbg)
        else:
            st.caption("**Transcription dÃ©tectÃ©e :**")
            st.write(msg)

            answer = chatbot(
                msg,
                st.session_state["sentences"],
                st.session_state["corpus_processed"],
                min_score=min_score
            )
            st.markdown("**RÃ©ponse du chatbot :**")
            st.success("RÃ©ponse trouvÃ©e âœ…")
            st.write(answer)
